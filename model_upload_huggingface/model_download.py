# from transformers import AutoModel, AutoTokenizer

# def download_huggingface_model(model_id: str, save_path: str = None, trust_remote_code: bool = False):
#     """
#     ä» Hugging Face Hub ä¸‹è½½æŒ‡å®šçš„æ¨¡å‹å’Œåˆ†è¯å™¨ã€‚

#     å‚æ•°:
#     model_id (str): Hugging Face Hub ä¸Šçš„æ¨¡å‹ID (ä¾‹å¦‚ "bert-base-uncased" æˆ– "HaoyeZhang/MLLM_Excercise_Model")ã€‚
#     save_path (str, optional): æ¨¡å‹å’Œåˆ†è¯å™¨ä¿å­˜çš„æœ¬åœ°è·¯å¾„ã€‚
#                                å¦‚æœä¸º None, æ¨¡å‹å°†ä¸‹è½½åˆ° Hugging Face çš„é»˜è®¤ç¼“å­˜ç›®å½•ã€‚
#                                å¦‚æœæä¾›äº†è·¯å¾„ï¼Œæ¨¡å‹å’Œåˆ†è¯å™¨å°†è¢«ä¿å­˜åœ¨æ­¤è·¯å¾„ä¸‹ã€‚
#     trust_remote_code (bool): æ˜¯å¦å…è®¸æ‰§è¡Œæ¨¡å‹ä»“åº“ä¸­çš„è‡ªå®šä¹‰ä»£ç ã€‚
#                               å¯¹äºæŸäº›æ¨¡å‹ (å¦‚ "HaoyeZhang/MLLM_Excercise_Model")ï¼Œè¿™å¯èƒ½æ˜¯å¿…éœ€çš„ã€‚
#                               è¯·è°¨æ…ä½¿ç”¨ï¼Œç¡®ä¿ä¿¡ä»»ä»£ç æ¥æºã€‚
#     """
#     print(f"å¼€å§‹å¤„ç†æ¨¡å‹: {model_id}")
#     if trust_remote_code:
#         print("æ³¨æ„: trust_remote_code=True å·²å¯ç”¨ã€‚è¿™æ„å‘³ç€å°†å…è®¸æ‰§è¡Œä»æ¨¡å‹ä»“åº“ä¸‹è½½çš„è‡ªå®šä¹‰ä»£ç ã€‚")
#         print("è¯·ç¡®ä¿æ‚¨å®Œå…¨ä¿¡ä»»æ­¤æ¨¡å‹çš„æ¥æºå’Œå…¶ä»£ç çš„å®‰å…¨æ€§ã€‚")

#     try:
#         # å°è¯•åŠ è½½/ä¸‹è½½æ¨¡å‹
#         print(f"æ­£åœ¨ä¸‹è½½/åŠ è½½æ¨¡å‹ '{model_id}'...")
#         # æ ¹æ®æ¨¡å‹ç±»å‹ï¼Œæ‚¨å¯èƒ½æƒ³ä½¿ç”¨ AutoModelForCausalLM, AutoModelForSeq2SeqLM ç­‰ï¼Œ
#         # ä½† AutoModel é€šå¸¸è¶³ä»¥ç”¨äºä¸‹è½½æƒé‡ã€‚
#         model = AutoModel.from_pretrained(model_id, trust_remote_code=trust_remote_code)
#         print(f"æ¨¡å‹ '{model_id}' ä¸‹è½½/åŠ è½½æˆåŠŸã€‚")

#         # å°è¯•åŠ è½½/ä¸‹è½½åˆ†è¯å™¨
#         print(f"æ­£åœ¨ä¸‹è½½/åŠ è½½åˆ†è¯å™¨ '{model_id}'...")
#         try:
#             tokenizer = AutoTokenizer.from_pretrained(model_id, trust_remote_code=trust_remote_code)
#             print(f"åˆ†è¯å™¨ '{model_id}' ä¸‹è½½/åŠ è½½æˆåŠŸã€‚")
#         except Exception as e:
#             print(f"è­¦å‘Š: æ— æ³•ä¸º '{model_id}' åŠ è½½æ ‡å‡†åˆ†è¯å™¨ã€‚é”™è¯¯: {e}")
#             print("è¿™å¯èƒ½æ˜¯å› ä¸ºè¯¥æ¨¡å‹æ²¡æœ‰æ ‡å‡†åˆ†è¯å™¨ï¼Œæˆ–è€…åˆ†è¯å™¨é…ç½®ä¸åŒã€‚")
#             print("å¦‚æœæ¨¡å‹æ˜¯å¤šæ¨¡æ€çš„ï¼Œå¯èƒ½éœ€è¦ç‰¹å®šçš„é¢„å¤„ç†å™¨è€Œä¸æ˜¯æ ‡å‡†åˆ†è¯å™¨ã€‚")
#             print("å¯¹äºæŸäº›æ¨¡å‹ï¼Œåˆ†è¯å™¨å¯èƒ½ä¸éœ€è¦ trust_remote_code=Trueï¼Œå³ä½¿æ¨¡å‹æœ¬èº«éœ€è¦ã€‚")
#             tokenizer = None

#         if save_path:
#             print(f"æ­£åœ¨å°†æ¨¡å‹å’Œåˆ†è¯å™¨ä¿å­˜åˆ°ç›®å½•: {save_path}")
#             model.save_pretrained(save_path)
#             if tokenizer:
#                 tokenizer.save_pretrained(save_path)
#             print(f"æ¨¡å‹å’Œåˆ†è¯å™¨å·²æˆåŠŸä¿å­˜åˆ°: {save_path}")
#         else:
#             print(f"æ¨¡å‹å’Œåˆ†è¯å™¨å·²ä¸‹è½½åˆ° Hugging Face é»˜è®¤ç¼“å­˜ç›®å½•ã€‚")
#             print(f"æ‚¨é€šå¸¸å¯ä»¥åœ¨ ~/.cache/huggingface/hub (æˆ–ç±»ä¼¼è·¯å¾„) æ‰¾åˆ°å®ƒä»¬ã€‚")

#     except Exception as e:
#         print(f"ä¸‹è½½æˆ–åŠ è½½æ¨¡å‹ '{model_id}' å¤±è´¥ã€‚é”™è¯¯: {e}")
#         print("è¯·æ£€æŸ¥ä»¥ä¸‹å‡ ç‚¹:")
#         print(f"  1. æ¨¡å‹ID '{model_id}' æ˜¯å¦æ­£ç¡®æ— è¯¯ã€‚")
#         print("  2. æ‚¨çš„è®¾å¤‡æ˜¯å¦æœ‰ç¨³å®šçš„ç½‘ç»œè¿æ¥ã€‚")
#         print(f"  3. å¯¹äºæ¨¡å‹ '{model_id}'ï¼Œå¯èƒ½éœ€è¦è®¾ç½® trust_remote_code=Trueã€‚")
#         print(f"     å½“å‰è®¾ç½®: trust_remote_code={trust_remote_code}")
#         print("     å¦‚æœé”™è¯¯ä¿¡æ¯ä¸­æåŠ 'remote code' æˆ–ç±»ä¼¼å†…å®¹ï¼Œè¯·å°è¯•åœ¨è°ƒç”¨å‡½æ•°æ—¶å°† trust_remote_code è®¾ç½®ä¸º Trueã€‚")
#         print("     ä¾‹å¦‚: download_huggingface_model(model_id, trust_remote_code=True)")

# if __name__ == "__main__":
#     # è¦ä¸‹è½½çš„æ¨¡å‹çš„ID
#     model_id_to_download = "HaoyeZhang/MLLM_Excercise_Model"

#     # å¯¹äº "HaoyeZhang/MLLM_Excercise_Model"ï¼Œå®ƒæ˜¯ä¸€ä¸ªåŸºäºLlamaçš„è‡ªå®šä¹‰æ¨¡å‹ï¼Œ
#     # å› æ­¤éå¸¸å¯èƒ½éœ€è¦ trust_remote_code=True æ‰èƒ½æ­£ç¡®åŠ è½½ã€‚
#     # **é‡è¦å®‰å…¨æç¤º**: å¯ç”¨ trust_remote_code=True æ—¶ï¼Œæ‚¨æ­£åœ¨å…è®¸æ‰§è¡Œä»æ¨¡å‹ä»“åº“ä¸‹è½½çš„Pythonä»£ç ã€‚
#     #                  è¯·åŠ¡å¿…ç¡®ä¿æ‚¨ä¿¡ä»»è¯¥æ¨¡å‹çš„æ¥æº (Hugging Face ç”¨æˆ· "HaoyeZhang") åŠå…¶æä¾›çš„ä»£ç ã€‚
#     #                  å¦‚æœæ‚¨ä¸ç¡®å®šï¼Œè¯·å…ˆåœ¨éš”ç¦»ç¯å¢ƒä¸­è¿›è¡Œæµ‹è¯•ã€‚
#     should_trust_remote_code = True

#     print(f"å‡†å¤‡ä¸‹è½½æ¨¡å‹: {model_id_to_download}")
#     print(f"å°†ä½¿ç”¨ trust_remote_code={should_trust_remote_code} (è¯·é˜…è¯»ä¸Šè¿°å®‰å…¨æç¤º)")
#     print("-" * 50)

#     # # è°ƒç”¨å‡½æ•°ä¸‹è½½æ¨¡å‹ã€‚é»˜è®¤æƒ…å†µä¸‹ï¼Œè¿™å°†ä¸‹è½½åˆ° Hugging Face çš„ç¼“å­˜ç›®å½•ã€‚
#     # download_huggingface_model(
#     #     model_id_to_download,
#     #     trust_remote_code=should_trust_remote_code
#     # )

#     # --- å¯é€‰ï¼šä¸‹è½½å¹¶ä¿å­˜åˆ°æŒ‡å®šæ–‡ä»¶å¤¹ ---
#     # å¦‚æœæ‚¨æƒ³å°†æ¨¡å‹æ–‡ä»¶ä¿å­˜åˆ°ä¸€ä¸ªç‰¹å®šçš„æœ¬åœ°æ–‡ä»¶å¤¹ï¼Œè€Œä¸æ˜¯Hugging Faceçš„é»˜è®¤ç¼“å­˜ï¼Œ
#     # å¯ä»¥å–æ¶ˆæ³¨é‡Šä¸‹é¢çš„ä»£ç å—ï¼Œå¹¶è®¾ç½® `custom_save_directory` å˜é‡ã€‚

#     # custom_save_directory = "./downloaded_models/MLLM_Excercise_Model_files" # æ‚¨å¯ä»¥è‡ªå®šä¹‰æ­¤è·¯å¾„
#     # print(f"\nå‡†å¤‡å°†æ¨¡å‹ä¸‹è½½å¹¶ä¿å­˜åˆ°è‡ªå®šä¹‰ç›®å½•: {custom_save_directory}")
#     # print(f"å°†ä½¿ç”¨ trust_remote_code={should_trust_remote_code}")
#     # print("-" * 50)
#     # download_huggingface_model(
#     #     model_id_to_download,
#     #     save_path=custom_save_directory,
#     #     trust_remote_code=should_trust_remote_code
#     # )

#     print("-" * 50)
#     print("è„šæœ¬æ‰§è¡Œå®Œæ¯•ã€‚")



import os
import requests
from tqdm import tqdm
from huggingface_hub import HfApi, snapshot_download
from concurrent.futures import ThreadPoolExecutor
import argparse
import hashlib

def get_model_files(repo_id, token=None):
    """è·å–æ¨¡å‹ä»“åº“çš„æ‰€æœ‰æ–‡ä»¶åˆ—è¡¨"""
    api = HfApi()
    files = api.list_repo_files(repo_id, token=token)
    return [f for f in files if not f.endswith(('.json', '.txt', '.md'))]  # è¿‡æ»¤æ‰å°æ–‡ä»¶

def download_file(url, local_path, token=None, chunk_size=8192):
    """ä¸‹è½½å•ä¸ªæ–‡ä»¶ï¼ˆæ”¯æŒæ–­ç‚¹ç»­ä¼ ï¼‰"""
    headers = {}
    if token:
        headers["Authorization"] = f"Bearer {token}"
    
    # æ£€æŸ¥å·²ä¸‹è½½éƒ¨åˆ†
    if os.path.exists(local_path):
        existing_size = os.path.getsize(local_path)
        headers["Range"] = f"bytes={existing_size}-"
    else:
        existing_size = 0

    with requests.get(url, headers=headers, stream=True) as r:
        r.raise_for_status()
        total_size = int(r.headers.get('content-length', 0)) + existing_size
        
        # æ£€æŸ¥æ˜¯å¦æ”¯æŒæ–­ç‚¹ç»­ä¼ 
        mode = 'ab' if existing_size else 'wb'
        
        with open(local_path, mode) as f, tqdm(
            desc=os.path.basename(local_path),
            total=total_size,
            unit='B',
            unit_scale=True,
            unit_divisor=1024,
            initial=existing_size
        ) as progress:
            for chunk in r.iter_content(chunk_size=chunk_size):
                f.write(chunk)
                progress.update(len(chunk))

def download_model(
    repo_id,
    save_dir="models",
    token=None,
    max_workers=4,
    revision="main",
    ignore_patterns=[]
):
    """
    ä¸‹è½½Hugging Faceå¤§æ¨¡å‹
    
    å‚æ•°:
        repo_id: æ¨¡å‹ID (å¦‚ "meta-llama/Llama-2-7b-chat-hf")
        save_dir: æœ¬åœ°ä¿å­˜ç›®å½•
        token: HFè®¿é—®ä»¤ç‰Œï¼ˆç§æœ‰æ¨¡å‹éœ€è¦ï¼‰
        max_workers: å¹¶å‘ä¸‹è½½çº¿ç¨‹æ•°
        revision: æ¨¡å‹ç‰ˆæœ¬/åˆ†æ”¯
        ignore_patterns: å¿½ç•¥çš„æ–‡ä»¶æ¨¡å¼
    """
    os.makedirs(save_dir, exist_ok=True)
    
    print(f"â³ æ­£åœ¨è·å–æ¨¡å‹æ–‡ä»¶åˆ—è¡¨: {repo_id}")
    api = HfApi()
    
    # ä½¿ç”¨snapshot_downloadè·å–æ–‡ä»¶URLs
    cache_dir = snapshot_download(
        repo_id=repo_id,
        revision=revision,
        token=token,
        local_dir=save_dir,
        ignore_patterns=ignore_patterns,
        local_dir_use_symlinks=False,
        resume_download=True
    )
    
    print(f"âœ… æ¨¡å‹å·²ä¸‹è½½åˆ°: {cache_dir}")
    return cache_dir

def verify_model(repo_id, save_dir):
    """éªŒè¯ä¸‹è½½æ–‡ä»¶çš„å®Œæ•´æ€§ï¼ˆå¯é€‰ï¼‰"""
    print("ğŸ” æ­£åœ¨éªŒè¯æ¨¡å‹æ–‡ä»¶...")
    api = HfApi()
    files = api.list_repo_files(repo_id)
    
    for file in files:
        if file.endswith(('.json', '.txt', '.md')):
            continue
            
        local_path = os.path.join(save_dir, file)
        if not os.path.exists(local_path):
            print(f"âŒ æ–‡ä»¶ç¼ºå¤±: {file}")
            return False
            
        # è¿™é‡Œå¯ä»¥æ·»åŠ SHA256æ ¡éªŒï¼ˆå¦‚æœHFæä¾›ï¼‰
        # ...
    
    print("âœ… æ‰€æœ‰æ–‡ä»¶éªŒè¯é€šè¿‡")
    return True

if __name__ == "__main__":
    parser = argparse.ArgumentParser(description='ä¸‹è½½Hugging Faceå¤§æ¨¡å‹')
    parser.add_argument('--repo_id', type=str, help='æ¨¡å‹ID (å¦‚ "meta-llama/Llama-2-7b-chat-hf")')
    parser.add_argument('--save_dir', type=str, default="models", help='æœ¬åœ°ä¿å­˜ç›®å½•')
    parser.add_argument('--token', type=str, default=None, help='HFè®¿é—®ä»¤ç‰Œ')
    parser.add_argument('--revision', type=str, default="main", help='æ¨¡å‹ç‰ˆæœ¬/åˆ†æ”¯')
    parser.add_argument('--max_workers', type=int, default=4, help='å¹¶å‘ä¸‹è½½çº¿ç¨‹æ•°')
    
    args = parser.parse_args()
    
    # ä¸‹è½½æ¨¡å‹
    model_path = download_model(
        repo_id=args.repo_id,
        save_dir=args.save_dir,
        token=args.token,
        max_workers=args.max_workers,
        revision=args.revision
    )
    
    # éªŒè¯ä¸‹è½½
    verify_model(args.repo_id, model_path)